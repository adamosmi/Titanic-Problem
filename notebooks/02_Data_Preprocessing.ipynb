{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this notebook, we'll conduct a series of steps necessary to prepare ourIn this notebook, we'll conduct a series of steps necessary to prepare our Titanic dataset for model training. This includes handling missing data, transforming certain features, and encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "# Print the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Let's start by examining how much missing data we have and decide how to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Age, Cabin, and Embarked have missing values. Let's handle each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of \"Age\" column: 28.0\n",
      "Mode of \"Embarked\" column: S\n"
     ]
    }
   ],
   "source": [
    "# Use median to fill missing values in Age\n",
    "median_age = df['Age'].median()\n",
    "print(f'Median of \"Age\" column: {median_age}')\n",
    "df['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "# Fill missing values in Embarked with the mode\n",
    "mode_embarked = df['Embarked'].mode()[0]\n",
    "print(f'Mode of \"Embarked\" column: {mode_embarked}')\n",
    "df['Embarked'].fillna(mode_embarked, inplace=True)\n",
    "\n",
    "# Too many missing values in Cabin, drop the column\n",
    "df = df.drop('Cabin', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation\n",
    "\n",
    "Let's transform some of the features to better suit our modeling needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine SibSp and Parch into a single feature FamilySize\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "df = df.drop(['SibSp', 'Parch'], axis=1)\n",
    "\n",
    "# Transform Fare to log scale due to high skewness\n",
    "df['Fare'] = df['Fare'].apply(lambda x: np.log(x) if x > 0 else 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding\n",
    "\n",
    "Finally, let's handle our categorical variables. We'll perform one-hot encoding on the Embarked and Pclass columns, and encode the Sex column to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for Embarked and Pclass\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Pclass'])\n",
    "\n",
    "# Binary encoding for Sex\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract titles from the Name column as it might indicate social status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract titles from name\n",
    "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df = df.drop(['Name'], axis=1)\n",
    "\n",
    "# One-hot encoding for Title\n",
    "df = pd.get_dummies(df, columns=['Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Ticket' field in the Titanic dataset represents the ticket number for each passenger. At first glance, this seems like an arbitrary string that might not have much information. However, upon further investigation, some potential patterns and useful information could be extracted:\n",
    "\n",
    "Ticket Prefix: Some tickets have prefixes which may denote some sort of classification, possibly related to the cabin, embarkation point, or passenger type. You could try extracting these prefixes and see if they provide any additional value to your model.\n",
    "\n",
    "Shared Tickets: Passengers traveling together often have the same ticket number. This could help us derive a feature that represents groups or families traveling together.\n",
    "\n",
    "Ticket Length: The length of the ticket number (including the prefix) could also potentially hold some information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ticket prefix\n",
    "df['Ticket_Prefix'] = df['Ticket'].apply(lambda x: x.split()[0] if not x.split()[0].isdigit() else 'NoPrefix')\n",
    "df = df.drop(['Ticket'], axis=1)\n",
    "\n",
    "# One-hot encoding for Ticket_Prefix\n",
    "df = pd.get_dummies(df, columns=['Ticket_Prefix'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our processed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Prefix_SOTON/O.Q.</th>\n",
       "      <th>Ticket_Prefix_SOTON/O2</th>\n",
       "      <th>Ticket_Prefix_SOTON/OQ</th>\n",
       "      <th>Ticket_Prefix_STON/O</th>\n",
       "      <th>Ticket_Prefix_STON/O2.</th>\n",
       "      <th>Ticket_Prefix_SW/PP</th>\n",
       "      <th>Ticket_Prefix_W./C.</th>\n",
       "      <th>Ticket_Prefix_W.E.P.</th>\n",
       "      <th>Ticket_Prefix_W/C</th>\n",
       "      <th>Ticket_Prefix_WE/P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex   Age      Fare  FamilySize  Embarked_C  \\\n",
       "0            1         0    0  22.0  1.981001           1           0   \n",
       "1            2         1    1  38.0  4.266662           1           1   \n",
       "2            3         1    1  26.0  2.070022           0           0   \n",
       "3            4         1    1  35.0  3.972177           1           0   \n",
       "4            5         0    0  35.0  2.085672           0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Pclass_1  ...  Ticket_Prefix_SOTON/O.Q.  \\\n",
       "0           0           1         0  ...                         0   \n",
       "1           0           0         1  ...                         0   \n",
       "2           0           1         0  ...                         0   \n",
       "3           0           1         1  ...                         0   \n",
       "4           0           1         0  ...                         0   \n",
       "\n",
       "   Ticket_Prefix_SOTON/O2  Ticket_Prefix_SOTON/OQ  Ticket_Prefix_STON/O  \\\n",
       "0                       0                       0                     0   \n",
       "1                       0                       0                     0   \n",
       "2                       0                       0                     0   \n",
       "3                       0                       0                     0   \n",
       "4                       0                       0                     0   \n",
       "\n",
       "   Ticket_Prefix_STON/O2.  Ticket_Prefix_SW/PP  Ticket_Prefix_W./C.  \\\n",
       "0                       0                    0                    0   \n",
       "1                       0                    0                    0   \n",
       "2                       1                    0                    0   \n",
       "3                       0                    0                    0   \n",
       "4                       0                    0                    0   \n",
       "\n",
       "   Ticket_Prefix_W.E.P.  Ticket_Prefix_W/C  Ticket_Prefix_WE/P  \n",
       "0                     0                  0                   0  \n",
       "1                     0                  0                   0  \n",
       "2                     0                  0                   0  \n",
       "3                     0                  0                   0  \n",
       "4                     0                  0                   0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 73 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   PassengerId               891 non-null    int64  \n",
      " 1   Survived                  891 non-null    int64  \n",
      " 2   Sex                       891 non-null    int64  \n",
      " 3   Age                       891 non-null    float64\n",
      " 4   Fare                      891 non-null    float64\n",
      " 5   FamilySize                891 non-null    int64  \n",
      " 6   Embarked_C                891 non-null    uint8  \n",
      " 7   Embarked_Q                891 non-null    uint8  \n",
      " 8   Embarked_S                891 non-null    uint8  \n",
      " 9   Pclass_1                  891 non-null    uint8  \n",
      " 10  Pclass_2                  891 non-null    uint8  \n",
      " 11  Pclass_3                  891 non-null    uint8  \n",
      " 12  Title_Capt                891 non-null    uint8  \n",
      " 13  Title_Col                 891 non-null    uint8  \n",
      " 14  Title_Countess            891 non-null    uint8  \n",
      " 15  Title_Don                 891 non-null    uint8  \n",
      " 16  Title_Dr                  891 non-null    uint8  \n",
      " 17  Title_Jonkheer            891 non-null    uint8  \n",
      " 18  Title_Lady                891 non-null    uint8  \n",
      " 19  Title_Major               891 non-null    uint8  \n",
      " 20  Title_Master              891 non-null    uint8  \n",
      " 21  Title_Miss                891 non-null    uint8  \n",
      " 22  Title_Mlle                891 non-null    uint8  \n",
      " 23  Title_Mme                 891 non-null    uint8  \n",
      " 24  Title_Mr                  891 non-null    uint8  \n",
      " 25  Title_Mrs                 891 non-null    uint8  \n",
      " 26  Title_Ms                  891 non-null    uint8  \n",
      " 27  Title_Rev                 891 non-null    uint8  \n",
      " 28  Title_Sir                 891 non-null    uint8  \n",
      " 29  Ticket_Prefix_A./5.       891 non-null    uint8  \n",
      " 30  Ticket_Prefix_A.5.        891 non-null    uint8  \n",
      " 31  Ticket_Prefix_A/4         891 non-null    uint8  \n",
      " 32  Ticket_Prefix_A/4.        891 non-null    uint8  \n",
      " 33  Ticket_Prefix_A/5         891 non-null    uint8  \n",
      " 34  Ticket_Prefix_A/5.        891 non-null    uint8  \n",
      " 35  Ticket_Prefix_A/S         891 non-null    uint8  \n",
      " 36  Ticket_Prefix_A4.         891 non-null    uint8  \n",
      " 37  Ticket_Prefix_C           891 non-null    uint8  \n",
      " 38  Ticket_Prefix_C.A.        891 non-null    uint8  \n",
      " 39  Ticket_Prefix_C.A./SOTON  891 non-null    uint8  \n",
      " 40  Ticket_Prefix_CA          891 non-null    uint8  \n",
      " 41  Ticket_Prefix_CA.         891 non-null    uint8  \n",
      " 42  Ticket_Prefix_F.C.        891 non-null    uint8  \n",
      " 43  Ticket_Prefix_F.C.C.      891 non-null    uint8  \n",
      " 44  Ticket_Prefix_Fa          891 non-null    uint8  \n",
      " 45  Ticket_Prefix_LINE        891 non-null    uint8  \n",
      " 46  Ticket_Prefix_NoPrefix    891 non-null    uint8  \n",
      " 47  Ticket_Prefix_P/PP        891 non-null    uint8  \n",
      " 48  Ticket_Prefix_PC          891 non-null    uint8  \n",
      " 49  Ticket_Prefix_PP          891 non-null    uint8  \n",
      " 50  Ticket_Prefix_S.C./A.4.   891 non-null    uint8  \n",
      " 51  Ticket_Prefix_S.C./PARIS  891 non-null    uint8  \n",
      " 52  Ticket_Prefix_S.O./P.P.   891 non-null    uint8  \n",
      " 53  Ticket_Prefix_S.O.C.      891 non-null    uint8  \n",
      " 54  Ticket_Prefix_S.O.P.      891 non-null    uint8  \n",
      " 55  Ticket_Prefix_S.P.        891 non-null    uint8  \n",
      " 56  Ticket_Prefix_S.W./PP     891 non-null    uint8  \n",
      " 57  Ticket_Prefix_SC          891 non-null    uint8  \n",
      " 58  Ticket_Prefix_SC/AH       891 non-null    uint8  \n",
      " 59  Ticket_Prefix_SC/PARIS    891 non-null    uint8  \n",
      " 60  Ticket_Prefix_SC/Paris    891 non-null    uint8  \n",
      " 61  Ticket_Prefix_SCO/W       891 non-null    uint8  \n",
      " 62  Ticket_Prefix_SO/C        891 non-null    uint8  \n",
      " 63  Ticket_Prefix_SOTON/O.Q.  891 non-null    uint8  \n",
      " 64  Ticket_Prefix_SOTON/O2    891 non-null    uint8  \n",
      " 65  Ticket_Prefix_SOTON/OQ    891 non-null    uint8  \n",
      " 66  Ticket_Prefix_STON/O      891 non-null    uint8  \n",
      " 67  Ticket_Prefix_STON/O2.    891 non-null    uint8  \n",
      " 68  Ticket_Prefix_SW/PP       891 non-null    uint8  \n",
      " 69  Ticket_Prefix_W./C.       891 non-null    uint8  \n",
      " 70  Ticket_Prefix_W.E.P.      891 non-null    uint8  \n",
      " 71  Ticket_Prefix_W/C         891 non-null    uint8  \n",
      " 72  Ticket_Prefix_WE/P        891 non-null    uint8  \n",
      "dtypes: float64(2), int64(4), uint8(67)\n",
      "memory usage: 100.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/train_processed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for model training!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
